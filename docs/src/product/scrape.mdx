---
title: Scrape
description: Extract structured data from websites using AI-powered scraping
---

Notte's Scrape feature uses AI to extract structured data from web pages, turning unstructured HTML into clean, usable data formats.

## What is Scrape?

Scrape allows you to:

- **Extract** data using natural language instructions
- **Structure** data into Pydantic models
- **Parse** complex layouts automatically
- **Handle** dynamic content
- **Scale** across multiple pages

## Quick Start

Extract data with a simple instruction:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient

  client = NotteClient()

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/products")

      # Extract data with natural language
      data = session.scrape(
          instructions="Extract all product names and prices"
      )

      print(data)
  ```
</CodeGroup>

## Structured Scraping

Define the exact structure you want:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel

  client = NotteClient()

  # Define your data model
  class Product(BaseModel):
      name: str
      price: float
      in_stock: bool

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/products")

      # Extract into structured format
      products = session.scrape(
          response_format=list[Product],
          instructions="Extract all products with their details"
      )

      for product in products:
          print(f"{product.name}: ${product.price}")
  ```
</CodeGroup>

## Scraping Modes

### Basic Scraping

Get raw markdown content:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient

  client = NotteClient()

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com")

      # Get markdown of the page
      markdown = session.scrape()

      print(markdown)
  ```
</CodeGroup>

### Instructed Scraping

Use natural language to guide extraction:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient

  client = NotteClient()

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/blog")

      # Use instructions
      articles = session.scrape(
          instructions="Get the titles, authors, and publication dates of all blog posts"
      )

      print(articles)
  ```
</CodeGroup>

### Structured Scraping

Extract into Pydantic models for type safety:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel
  from datetime import date

  client = NotteClient()

  class Article(BaseModel):
      title: str
      author: str
      published_date: date
      summary: str

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/blog")

      articles = session.scrape(
          response_format=list[Article],
          instructions="Extract blog articles"
      )

      for article in articles:
          print(f"{article.title} by {article.author}")
  ```
</CodeGroup>

## Use Cases

### 1. E-commerce Scraping

Extract product information:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel

  client = NotteClient()

  class Product(BaseModel):
      name: str
      price: float
      rating: float
      reviews_count: int
      in_stock: bool

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/category/laptops")

      products = session.scrape(
          response_format=list[Product],
          instructions="Extract all laptop products"
      )

      # Filter and analyze
      affordable = [p for p in products if p.price < 1000]
      print(f"Found {len(affordable)} laptops under $1000")
  ```
</CodeGroup>

### 2. Lead Generation

Extract contact information:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel

  client = NotteClient()

  class Company(BaseModel):
      name: str
      email: str | None
      phone: str | None
      address: str | None

  with client.Session() as session:
      session.execute(type="goto", url="https://directory.example.com")

      companies = session.scrape(
          response_format=list[Company],
          instructions="Extract company contact information"
      )
  ```
</CodeGroup>

### 3. Price Monitoring

Track competitor prices:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel
  from datetime import datetime

  client = NotteClient()

  class PriceSnapshot(BaseModel):
      product: str
      price: float
      currency: str
      timestamp: datetime

  competitors = [
      "https://competitor1.com/products",
      "https://competitor2.com/products"
  ]

  all_prices = []

  for url in competitors:
      with client.Session() as session:
          session.execute(type="goto", url=url)

          prices = session.scrape(
              response_format=list[PriceSnapshot],
              instructions="Extract product names and prices"
          )

          all_prices.extend(prices)

  # Analyze prices
  avg_price = sum(p.price for p in all_prices) / len(all_prices)
  print(f"Average price: ${avg_price:.2f}")
  ```
</CodeGroup>

### 4. Content Aggregation

Collect articles or news:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel

  client = NotteClient()

  class NewsArticle(BaseModel):
      headline: str
      source: str
      published: str
      url: str

  with client.Session() as session:
      session.execute(type="goto", url="https://news.example.com")

      articles = session.scrape(
          response_format=list[NewsArticle],
          instructions="Get today's top news headlines"
      )

      for article in articles:
          print(f"[{article.source}] {article.headline}")
  ```
</CodeGroup>

## Advanced Features

### Pagination

Scrape across multiple pages:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient

  client = NotteClient()

  all_products = []

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/products")

      for page in range(1, 6):  # Scrape 5 pages
          products = session.scrape(
              instructions="Extract all products on this page"
          )

          all_products.extend(products)

          # Go to next page
          session.execute(type="click", selector="a.next-page")

  print(f"Total products: {len(all_products)}")
  ```
</CodeGroup>

### Filtering

Extract only relevant data:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient

  client = NotteClient()

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/jobs")

      jobs = session.scrape(
          instructions="Extract only remote software engineering jobs posted in the last 7 days"
      )
  ```
</CodeGroup>

### Nested Structures

Extract complex hierarchical data:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient
  from pydantic import BaseModel

  client = NotteClient()

  class Review(BaseModel):
      author: str
      rating: int
      comment: str

  class Product(BaseModel):
      name: str
      price: float
      reviews: list[Review]

  with client.Session() as session:
      session.execute(type="goto", url="https://example.com/product/123")

      product = session.scrape(
          response_format=Product,
          instructions="Extract product details including all reviews"
      )

      print(f"{product.name}: {len(product.reviews)} reviews")
  ```
</CodeGroup>

## Scraping Best Practices

### 1. Be Specific

Provide clear, detailed instructions:

```python
# Good: Specific
instructions = "Extract product name, price in USD, and average rating from 1-5 stars"

# Bad: Vague
instructions = "Get product info"
```

### 2. Use Pydantic Models

Define strict schemas for consistent data:

```python
class Product(BaseModel):
    name: str
    price: float  # Enforces numeric type
    in_stock: bool  # Enforces boolean

# Type-safe extraction
products = session.scrape(response_format=list[Product], ...)
```

### 3. Handle Missing Data

Account for optional fields:

```python
class Product(BaseModel):
    name: str
    price: float
    discount: float | None = None  # Optional field
    rating: float | None = None
```

### 4. Validate Results

Check extracted data quality:

```python
products = session.scrape(...)

# Validate
valid_products = [p for p in products if p.price > 0]
print(f"Valid products: {len(valid_products)}/{len(products)}")
```

### 5. Optimize Performance

Only scrape what you need:

```python
# Good: Target specific content
data = session.scrape(
    instructions="Only extract items in the main content area",
    only_main_content=True
)

# Bad: Scrape everything
data = session.scrape()  # Gets entire page
```

## Scraping Limitations

What Scrape can do:
- ✅ Extract visible text content
- ✅ Parse tables and lists
- ✅ Handle dynamic JavaScript content
- ✅ Structure data with AI
- ✅ Follow pagination

What Scrape cannot do:
- ❌ Extract from images (without OCR)
- ❌ Access password-protected content (without login)
- ❌ Guarantee 100% accuracy
- ❌ Bypass anti-scraping measures alone
- ❌ Extract from PDFs (use specialized tools)

## Performance Tips

### 1. Use Main Content Only

Speed up scraping by targeting main content:

```python
data = session.scrape(
    instructions="Extract products",
    only_main_content=True  # Ignores headers, footers, sidebars
)
```

### 2. Batch Requests

Scrape multiple pages in one session:

```python
with client.Session() as session:
    for url in urls:
        session.execute(type="goto", url=url)
        data = session.scrape(...)
        # Process data
```

### 3. Cache Results

Avoid re-scraping unchanged content:

```python
import json
from pathlib import Path

cache_file = Path("cache.json")

if cache_file.exists():
    data = json.loads(cache_file.read_text())
else:
    data = session.scrape(...)
    cache_file.write_text(json.dumps(data))
```

## Combining Scrape with Agents

Let agents find and scrape data:

<CodeGroup>
  ```python Python
  from notte_sdk import NotteClient

  client = NotteClient()

  with client.Session() as session:
      # Agent navigates to data
      agent = client.Agent(session=session)
      agent.run(task="Navigate to the pricing page")

      # Scrape the data
      pricing = session.scrape(
          instructions="Extract all pricing plans with features"
      )

      print(pricing)
  ```
</CodeGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Agent Mode" icon="sparkles" href="/product/agent-mode">
    Let AI agents handle complex scraping
  </Card>

  <Card title="Functions" icon="bolt" href="/product/functions">
    Deploy scraping as API endpoints
  </Card>

  <Card title="Scraping Concept" icon="database" href="/concepts/scraping">
    Learn about scraping architecture
  </Card>

  <Card title="Scraping Guide" icon="book" href="/guides/scraping">
    Best practices for web scraping
  </Card>
</CardGroup>
